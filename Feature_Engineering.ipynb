{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaa03c26",
   "metadata": {},
   "source": [
    "# Feature Engineering (Spotify Track Data)  \n",
    "\n",
    "### Recategorize \"popularity\" target column for classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432bec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c86938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/spotify_cleaned.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9da729",
   "metadata": {},
   "source": [
    "### Before train-test-split: \n",
    "Popularity as target column needs to be **recategorized** for classification models:\n",
    "- \"New\" = values of -1 or 0, represents new songs or songs that have not been played on spotify yet for some reason\n",
    "- \"Low\", \"Medium\", \"High\" = by cutting 1/3rd (at 33, 66 and 100) the value ranges represent low, medium and high popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edada98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pd.cut for equal-width bins\n",
    "\n",
    "df['popularity_cat'] = pd.cut(df['popularity'],\n",
    "                                    bins=[-1, 0, 33, 66, 100],\n",
    "                                    labels=['New', 'Low', 'Medium', 'High'])\n",
    "\n",
    "print(df['popularity_cat'].value_counts())\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21f13ca",
   "metadata": {},
   "source": [
    "The categorization is unbalanced considering medium and low are dominating the popularity values (which has already been seen in the eda), but\n",
    "a balance class weight in a classification model probably fixes that. The categorization shouldn't become too complex. Will work with that for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine CAT_COLS for later one hot encoding (some may need to be dropped or go through a PCA first)\n",
    "\n",
    "CAT_COLS_NEW = [\n",
    "    'artists',\n",
    "    'album_name',\n",
    "    'track_name',\n",
    "    'explicit',\n",
    "    'track_genre',\n",
    "    'key',\n",
    "    'mode',\n",
    "    'time_signature']\n",
    "\n",
    "# check unique value count again\n",
    "print(f'{\"columns\":<20}{\"# unique values\"}')\n",
    "print('-'*40)\n",
    "for col in CAT_COLS_NEW:\n",
    "    print(f'{col:<20}{df[col].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ce2d55",
   "metadata": {},
   "source": [
    "### Notes for categorical columns & further feature engineering:\n",
    "- feature engineer new columns out of the 3 columns with too many unique values: \"artists\", \"album_name\", \"track_name\"\n",
    "    - Artist/Album Popularity: The popularity of an artist or album is derived from track popularity, which means tracks by highly popular artists or albums will tend to have higher popularity\n",
    "    - Convert track_name length to numeric since shorter or longer names can have an impact on popularity (track name like \"Burn\" vs. \"Fantasy on a long road\", etc.) and this way track_name data is somewhat usable for the model\n",
    "- use a pca for \"track_genre\" since 113 values is a bit too much for one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae940461",
   "metadata": {},
   "source": [
    "### Train-Test-Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split\n",
    "df_train, df_test = train_test_split(df, test_size = 0.3, random_state = 42)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf4adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second train-test-split for val/aim data\n",
    "df_test, df_aim = train_test_split(df_test, test_size = 0.33, random_state = 42)\n",
    "print(df_test.shape)\n",
    "print(df_aim.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebad689",
   "metadata": {},
   "source": [
    "### New features: Artist & Album Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c054947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mean track popularity per artist\n",
    "artist_popularity = df_train.groupby('artists')['popularity'].mean().to_dict()\n",
    "df_train['artist_popularity'] = df_train['artists'].map(artist_popularity)\n",
    "\n",
    "df_train['artist_popularity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mean track popularity per album\n",
    "artist_popularity = df_train.groupby('album_name')['popularity'].mean().to_dict()\n",
    "df_train['album_popularity'] = df_train['album_name'].map(artist_popularity)\n",
    "\n",
    "df_train['album_popularity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a8df8",
   "metadata": {},
   "source": [
    "### New feature: Track name length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce4b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lenght of track name for new column\n",
    "df_train['track_name_length'] = df_train['track_name'].str.len()\n",
    "\n",
    "df_train['track_name_length'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a84883",
   "metadata": {},
   "source": [
    "### PCA for track genres to reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8450fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode 'track_genre'\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "genre_encoded = ohe.fit_transform(df_train[['track_genre']])\n",
    "\n",
    "# apply pca\n",
    "n_variance = 0.90 # Keep up to 90% of the variance, test also with lower values\n",
    "\n",
    "pca = PCA(n_components=n_variance)  \n",
    "genre_pca = pca.fit_transform(genre_encoded)\n",
    "\n",
    "print(f\"Number of PCA components: {pca.n_components_}\")\n",
    "\n",
    "# create a DataFrame for PCA results\n",
    "genre_pca_df = pd.DataFrame(genre_pca, columns=[f'genre_pca_{i}' for i in range(pca.n_components_)], index=df_train.index)\n",
    "genre_pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee1bd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the explained variance ratio\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "ax.set_xlabel('Number of PCA Components')\n",
    "ax.set_ylabel('Cumulative Explained Variance')\n",
    "ax.set_title('Scree Plot: PCA on track_genre')\n",
    "ax.grid(True)\n",
    "ax.axhline(y=n_variance, color='r', linestyle='--', label=f'{n_variance*100}% threshold')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38155140",
   "metadata": {},
   "source": [
    "The pca for track_genre has not been very helpful. Let's try something else: Use mean of popularity (like for album popularity, for example) for each genre to create numerical values as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mean track popularity per genre\n",
    "genre_popularity = df_train.groupby('track_genre')['popularity'].mean()\n",
    "df_train['track_genre_pop'] = df_train['track_genre'].map(genre_popularity)\n",
    "\n",
    "df_train['track_genre_pop'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbd9ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff346f",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------\n",
    "Creating Classes / Functions for the engineered features to later use on df_test and val as well:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b91a97c",
   "metadata": {},
   "source": [
    "### to do: class creation for later pipeline (maybe in a bigger class even with subclasses?)\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ArtistPopularityTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.artist_pop_map_ = X.groupby('artists')['popularity'].mean()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['artist_popularity'] = X['artists'].map(self.artist_pop_map_)\n",
    "        return X\n",
    "\n",
    "transformer = ArtistPopularityTransformer()\n",
    "df_train = transformer.fit_transform(df_train)\n",
    "df_test = transformer.transform(df_test)\n",
    "\n",
    "### or just as functions (first fit, then transform):\n",
    "def fit_artist_popularity(df_train):\n",
    "    \"\"\"Creates a mapping of artist to their mean popularity.\"\"\"\n",
    "    return df_train.groupby('artists')['popularity'].mean()\n",
    "\n",
    "def add_artist_popularity_feature(df, artist_popularity_map):\n",
    "    \"\"\"Adds a new column to the DataFrame using the fitted artist popularity map.\"\"\"\n",
    "    df = df.copy()\n",
    "    df['artist_popularity'] = df['artists'].map(artist_popularity_map)\n",
    "    return df\n",
    "\n",
    "Fit on train only\n",
    "artist_popularity_map = fit_artist_popularity(df_train)\n",
    "\n",
    "Apply to both train and test (without re-fitting)\n",
    "df_train = add_artist_popularity_feature(df_train, artist_popularity_map)\n",
    "df_test = add_artist_popularity_feature(df_test, artist_popularity_map)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
