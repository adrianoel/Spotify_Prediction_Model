{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fab174b",
   "metadata": {},
   "source": [
    "# Base model\n",
    "\n",
    "Final base model will be built and tested. Feature engineering is applied; numerical features are standardized.  \n",
    "No Hyperparameter-Tuning yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0550f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('data/spotify_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485dffab",
   "metadata": {},
   "source": [
    "### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52884b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "df_train, df_test = train_test_split(df, test_size = 0.3, random_state = 42)\n",
    "\n",
    "print('df_train: ', df_train.shape)\n",
    "print('df_test: ', df_test.shape)\n",
    "\n",
    "# Second Train-Test-Split for val/aim data\n",
    "df_test, df_val = train_test_split(df_test, test_size=0.33, random_state = 42)\n",
    "\n",
    "print('df_test: ', df_test.shape)\n",
    "print('df_val: ', df_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e8a88e",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe6327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.clean_data_func import clean_data\n",
    "\n",
    "#apply clean_data function on train data\n",
    "df_train_cleaned = clean_data(df_train)\n",
    "display(df_train_cleaned.head())\n",
    "\n",
    "#apply clean_data function on test and val data\n",
    "df_test_cleaned = clean_data(df_test)\n",
    "df_val_cleaned = clean_data(df_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3697abbf",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ba3773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.feature_engineer_func import feature_engineer\n",
    "\n",
    "#apply feature_engineer function on train data\n",
    "df_train_final = feature_engineer(df_train_cleaned)\n",
    "display(df_train_final.head())\n",
    "\n",
    "#apply feature_engineer function on test and val data\n",
    "df_test_final = feature_engineer(df_test_cleaned)\n",
    "df_val_final = feature_engineer(df_val_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d136e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting train data into features and target without further feature engineering\n",
    "features_to_drop = [\n",
    "    'track_id',\n",
    "    'artists',\n",
    "    'album_name',\n",
    "    'track_name',\n",
    "    'track_genre',\n",
    "    'popularity',\n",
    "    'popularity_cat']\n",
    "\n",
    "features_train = df_train_final.drop(features_to_drop, axis = 1)\n",
    "target_train = df_train_final['popularity_cat']\n",
    "\n",
    "# splitting test data into features and target\n",
    "features_test = df_test_final.drop(features_to_drop, axis = 1)\n",
    "target_test = df_test_final['popularity_cat']\n",
    "\n",
    "# splitting val data into features and target\n",
    "features_val = df_val_final.drop(features_to_drop, axis = 1)\n",
    "target_val = df_val_final['popularity_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20cc95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check features and target of train data\n",
    "display(features_train.head(), features_train.shape)\n",
    "display(target_train.head(), target_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717f4d9e",
   "metadata": {},
   "source": [
    "### Data preparation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab06b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting columns easy for copy-paste\n",
    "print(features_train.columns)\n",
    "\n",
    "# specific category (for onehotencoding) and num cols list for pipeline\n",
    "CAT_COLS = ['key', 'time_signature']\n",
    "\n",
    "NUM_COLS = [col for col in features_train.columns if col not in CAT_COLS]\n",
    "\n",
    "print(CAT_COLS)\n",
    "print(NUM_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4015c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining pipelines to test with different models\n",
    "# models of interest: Classifiers with \"balanced weight\" parameter, e.g. DecisionTreeClassifier, RandomForestClassifier, LogisticRegression, others?\n",
    "\n",
    "# preprocessing: scale numeric features, one-hot-encode categorical\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), NUM_COLS),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), CAT_COLS)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# pipeline #1: RandomForestClassifier\n",
    "pipeline_rfc = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59797f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model #1\n",
    "pipeline_rfc.fit(features_train, target_train)\n",
    "\n",
    "# predict on test data\n",
    "target_test_pred = pipeline_rfc.predict(features_test)\n",
    "\n",
    "# show metrics\n",
    "#print('Accuracy: ', accuracy_score(target_test, target_test_pred))\n",
    "#print('Precision: ', precision_score(target_test, target_test_pred, average='weighted'))\n",
    "#print('Recall: ', recall_score(target_test, target_test_pred, average='weighted'))\n",
    "#print('F1-Score: ', f1_score(target_test, target_test_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(target_test, target_test_pred), '\\n')\n",
    "print('Classification Report: \\n', classification_report(target_test, target_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f457247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on val data\n",
    "target_val_pred = pipeline_rfc.predict(features_val)\n",
    "\n",
    "# show metrics\n",
    "print('Confusion Matrix: \\n', confusion_matrix(target_val, target_val_pred), '\\n')\n",
    "print('Classification Report: \\n', classification_report(target_val, target_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c88d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save classification report of val data in results folder of src to load it in final base model for direct comparison\n",
    "final_model_classification_report = classification_report(target_val, target_val_pred, output_dict=True)\n",
    "final_model_classification_report = pd.DataFrame(final_model_classification_report).transpose()\n",
    "final_model_classification_report.columns = ['precision_final', 'recall_final', 'f1_score_final', 'support_final']\n",
    "final_model_classification_report.to_csv('src/results/final_model_classification_report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare classification report with simple baseline model (skip last 2 rows of macro avg and weighted avg)\n",
    "simple_baseline_report = pd.read_csv('src/results/simple_model_classification_report.csv', index_col=0, skiprows=[6, 7])\n",
    "final_model_report = pd.read_csv('src/results/final_model_classification_report.csv', index_col=0, skiprows=[6, 7])\n",
    "\n",
    "#display('Simple baseline model classification report:', simple_baseline_report)\n",
    "#display('Final model classification report:', final_model_report)\n",
    "\n",
    "reports_combined = pd.concat([simple_baseline_report, final_model_report], axis=1)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "reports_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0abc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cross validation score\n",
    "cv_results = cross_val_score(estimator=pipeline_rfc,\n",
    "                            X=features_train,\n",
    "                            y=target_train,\n",
    "                            cv=5,\n",
    "                            scoring='f1_weighted',\n",
    "                            n_jobs=-1)\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0628065f",
   "metadata": {},
   "source": [
    "### Model interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23340e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check feature_importances_\n",
    "\n",
    "# get the classifier and preprocessor\n",
    "model = pipeline_rfc.named_steps['classifier']\n",
    "preprocessor = pipeline_rfc.named_steps['preprocessor']\n",
    "\n",
    "# get feature names after ColumnTransformer\n",
    "num_features = preprocessor.transformers_[0][2]\n",
    "cat_features = preprocessor.transformers_[1][1].get_feature_names_out(preprocessor.transformers_[1][2])\n",
    "all_features = np.concatenate([num_features, cat_features])\n",
    "\n",
    "# get feature importances\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# combine into a DataFrame\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': all_features,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# plot top N\n",
    "top_n = 20\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.barh(feature_importances.head(top_n).iloc[::-1]['feature'],\n",
    "         feature_importances.head(top_n).iloc[::-1]['importance'])\n",
    "ax.set_xlabel(\"Feature Importance\")\n",
    "ax.set_title(f\"Top {top_n} features of final model\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958d59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing learning curve (could take some time)\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=RandomForestClassifier(class_weight='balanced', random_state = 42), \n",
    "                                                        X=features_train, \n",
    "                                                        y=target_train, \n",
    "                                                        cv=5, \n",
    "                                                        scoring='f1_weighted',\n",
    "                                                        n_jobs=-1,\n",
    "                                                        train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "\n",
    "train_sizes_lc = train_sizes\n",
    "train_mean_lc = train_scores.mean(axis=1)\n",
    "test_mean_lc = test_scores.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lc, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(train_sizes_lc, train_mean_lc, label=\"train\", color = 'red')\n",
    "ax.plot(train_sizes_lc, test_mean_lc, label=\"validation\", color = 'blue')\n",
    "\n",
    "ax.set_title(\"Learning Curve\")\n",
    "ax.set_xlabel(\"Training Set Size\")\n",
    "ax.set_ylabel(\"F1-Score (weighted)\")\n",
    "ax.legend(loc=\"best\")\n",
    "fig_lc;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
